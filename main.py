#!/usr/bin/env python3
# process_iptv.py - å¤„ç†IPTVæºæ–‡ä»¶å¹¶åˆ†ç±»å»é‡
import requests
import time
import os
import hashlib
from typing import List, Dict, Set, Tuple
from datetime import datetime
from collections import defaultdict


class IPTVProcessor:
    def __init__(self):
        # å®šä¹‰1ï¼šéœ€è¦å†™å…¥æ–‡ä»¶1çš„ç±»åˆ«
        self.categories_file1 = {
            "ç”µå½±", "æ–°é—»", "ä½“è‚²", "å°æ¹¾", "ä¸­å›½", 
            "é¦™æ¸¯", "éŸ©å›½", "å°åº¦", "æ—¥æœ¬", "è¶Šå—", 
            "æ³°å›½", "æ–°åŠ å¡", "è‹±å›½", "é©¬æ¥è¥¿äºš", 
            "å„¿ç«¥", "çºªå½•"
        }
        
        # å®šä¹‰2ï¼šéœ€è¦å†™å…¥æ–‡ä»¶2çš„ç±»åˆ«
        self.categories_file2 = {
            "ã€1ã€‘", "ã€2ã€‘", "ã€3ã€‘", "ã€4ã€‘", "ã€5ã€‘", 
            "ã€6ã€‘", "ã€7ã€‘", "ã€8ã€‘", "ã€9ã€‘", "ã€10ã€‘", 
            "ã€11ã€‘", "ã€12ã€‘", "ã€13ã€‘", "ã€14ã€‘", "ã€15ã€‘", "ã€16ã€‘"
        }
        
        # æºURLåˆ—è¡¨
        self.source_urls = [
            "https://raw.githubusercontent.com/FGBLH/FG/refs/heads/main/æ–¯ç‘ªç‰¹ç›´æ’­æº1",
            "https://raw.githubusercontent.com/FGBLH/FG/refs/heads/main/%E6%B5%B7%E8%A7%92%E7%A4%BE%E5%8C%BA%E5%8D%9A%E4%B8%BB(%E5%85%8D%E7%95%AA%E5%BC%BA)"
        ]
        
        # è¯·æ±‚å¤´
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/plain',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive'
        }
        
        # å­˜å‚¨å¤„ç†ç»“æœ
        self.file1_content = []  # å­˜å‚¨åˆ†ç±»åçš„åˆ†ç»„
        self.file2_content = []
        
        # å»é‡ç›¸å…³
        self.url_signatures = set()  # å­˜å‚¨URLçš„ç­¾åç”¨äºå»é‡
        self.channel_cache = {      # ç¼“å­˜æ¯ä¸ªæ–‡ä»¶ä¸­çš„é¢‘é“
            'file1': defaultdict(set),  # category -> set(channel_lines)
            'file2': defaultdict(set)
        }
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_urls': 0,
            'success_urls': 0,
            'duplicate_channels': 0,
            'unique_channels': 0,
            'file1_categories': set(),
            'file2_categories': set()
        }
    
    def fetch_content(self, url: str) -> Tuple[str, bool]:
        """ä»URLè·å–å†…å®¹ï¼Œè¿”å›å†…å®¹å’Œæ˜¯å¦æˆåŠŸ"""
        try:
            print(f"ğŸ“¡ æ­£åœ¨è·å–: {url}")
            response = requests.get(url, headers=self.headers, timeout=15)
            response.raise_for_status()
            
            # è®¡ç®—å†…å®¹ç­¾åç”¨äºå»é‡
            content_hash = hashlib.md5(response.content).hexdigest()
            if content_hash in self.url_signatures:
                print(f"âš ï¸  æ£€æµ‹åˆ°é‡å¤å†…å®¹ï¼Œè·³è¿‡: {url}")
                return "", False
                
            self.url_signatures.add(content_hash)
            self.stats['success_urls'] += 1
            return response.text, True
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ è·å–å¤±è´¥ {url}: {e}")
            return "", False
        except Exception as e:
            print(f"âŒ å¤„ç†URLæ—¶å‡ºé”™ {url}: {e}")
            return "", False
    
    def extract_channel_info(self, line: str) -> Tuple[str, str, str]:
        """ä»é¢‘é“è¡Œæå–ä¿¡æ¯ï¼Œè¿”å›(é¢‘é“å, URL, ç­¾å)"""
        parts = line.split(',')
        if len(parts) >= 2:
            channel_name = parts[0].strip()
            channel_url = parts[1].strip()
            # åˆ›å»ºé¢‘é“ç­¾åï¼ˆä½¿ç”¨åç§°å’ŒURLçš„hashï¼‰
            signature = hashlib.md5(f"{channel_name}:{channel_url}".encode()).hexdigest()
            return channel_name, channel_url, signature
        return "", "", ""
    
    def is_duplicate_channel(self, category: str, channel_line: str, file_type: str) -> bool:
        """æ£€æŸ¥é¢‘é“æ˜¯å¦é‡å¤"""
        _, _, signature = self.extract_channel_info(channel_line)
        if signature:
            if signature in self.channel_cache[file_type][category]:
                return True
            self.channel_cache[file_type][category].add(signature)
        return False
    
    def process_content(self, content: str):
        """å¤„ç†å†…å®¹å¹¶åˆ†ç±»å»é‡"""
        if not content:
            return
            
        current_group = []
        current_category = ""
        
        for line in content.splitlines():
            line = line.strip()
            if not line:
                continue
                
            # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ†ç»„æ ‡é¢˜è¡Œ
            if line.endswith(",#genre#"):
                # ä¿å­˜ä¸Šä¸€ä¸ªåˆ†ç»„
                if current_group and current_category:
                    self.classify_and_deduplicate(current_category, current_group)
                
                # å¼€å§‹æ–°åˆ†ç»„
                current_category = line.split(',')[0]
                current_group = [line]
            else:
                # æ·»åŠ é¢‘é“è¡Œåˆ°å½“å‰åˆ†ç»„
                if current_group is not None:
                    current_group.append(line)
        
        # å¤„ç†æœ€åä¸€ä¸ªåˆ†ç»„
        if current_group and current_category:
            self.classify_and_deduplicate(current_category, current_group)
    
    def classify_and_deduplicate(self, category: str, lines: List[str]):
        """åˆ†ç±»å¹¶å»é‡åˆ†ç»„"""
        if len(lines) <= 1:  # åªæœ‰æ ‡é¢˜æ²¡æœ‰é¢‘é“
            return
        
        # æ£€æŸ¥ç±»åˆ«å±äºå“ªä¸ªæ–‡ä»¶
        target_file = None
        for cat1 in self.categories_file1:
            if cat1 in category:
                target_file = 'file1'
                self.stats['file1_categories'].add(category)
                break
        
        if not target_file:
            for cat2 in self.categories_file2:
                if cat2 in category:
                    target_file = 'file2'
                    self.stats['file2_categories'].add(category)
                    break
        
        if not target_file:
            return  # ä¸åŒ¹é…ä»»ä½•ç±»åˆ«ï¼Œè·³è¿‡
        
        # å»é‡å¤„ç†
        unique_lines = [lines[0]]  # æ ‡é¢˜è¡Œ
        seen_channels = set()
        
        for channel_line in lines[1:]:
            if not self.is_duplicate_channel(category, channel_line, target_file):
                unique_lines.append(channel_line)
                self.stats['unique_channels'] += 1
            else:
                self.stats['duplicate_channels'] += 1
        
        # å¦‚æœæœ‰å®é™…é¢‘é“å†…å®¹ï¼Œæ·»åŠ åˆ°å¯¹åº”æ–‡ä»¶
        if len(unique_lines) > 1:
            if target_file == 'file1':
                self.file1_content.append({
                    "category": category,
                    "lines": unique_lines
                })
            else:
                self.file2_content.append({
                    "category": category,
                    "lines": unique_lines
                })
    
    def write_files(self):
        """å†™å…¥æ–‡ä»¶"""
        # å†™å…¥my1.txt
        self._write_single_file("my1.txt", self.file1_content, "æ–‡ä»¶1")
        
        # å†™å…¥my2.txt
        self._write_single_file("my2.txt", self.file2_content, "æ–‡ä»¶2")
    
    def _write_single_file(self, filename: str, content_list: List[Dict], file_desc: str):
        """å†™å…¥å•ä¸ªæ–‡ä»¶"""
        total_channels = sum(len(item["lines"]) - 1 for item in content_list)
        
        with open(filename, 'w', encoding='utf-8') as f:
            # å†™å…¥æ–‡ä»¶å¤´
            f.write(f"# IPTVæºæ–‡ä»¶ - {file_desc}\n")
            f.write(f"# ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"# æºURL: {', '.join(self.source_urls)}\n")
            f.write(f"# åˆ†ç»„æ•°é‡: {len(content_list)}\n")
            f.write(f"# é¢‘é“æ•°é‡: {total_channels}\n")
            f.write(f"# è¿‡æ»¤é‡å¤é¢‘é“: {self.stats['duplicate_channels']}\n")
            f.write("# " + "="*60 + "\n\n")
            
            # å†™å…¥å†…å®¹
            for item in content_list:
                for line in item["lines"]:
                    f.write(line + "\n")
                f.write("\n")  # åˆ†ç»„ä¹‹é—´ç©ºä¸€è¡Œ
        
        # è¾“å‡ºç»“æœ
        if total_channels > 0:
            print(f"âœ… {filename}: {len(content_list)}ä¸ªåˆ†ç»„, {total_channels}ä¸ªå”¯ä¸€é¢‘é“")
        else:
            print(f"âš ï¸  {filename}: æ²¡æœ‰å†…å®¹å¯å†™å…¥")
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(f"# {file_desc} - æš‚æ— å†…å®¹\n")
    
    def run(self):
        """ä¸»è¿è¡Œæ–¹æ³•"""
        print("="*60)
        print("ğŸ¬ IPTVæºæ–‡ä»¶å¤„ç†å·¥å…· (å¸¦å»é‡åŠŸèƒ½)")
        print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60)
        
        # è·å–å¹¶å¤„ç†æ‰€æœ‰æº
        self.stats['total_urls'] = len(self.source_urls)
        
        for idx, url in enumerate(self.source_urls, 1):
            print(f"\nğŸ“‹ å¤„ç†æº {idx}/{len(self.source_urls)}")
            content, success = self.fetch_content(url)
            if success and content:
                self.process_content(content)
                time.sleep(0.3)  # ç¤¼è²Œå»¶è¿Ÿ
        
        # å†™å…¥æ–‡ä»¶
        print("\nğŸ’¾ å†™å…¥æ–‡ä»¶...")
        self.write_files()
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        self.print_statistics()
        
        print("="*60)
        print("ğŸ‰ å¤„ç†å®Œæˆ!")
        print("="*60)
    
    def print_statistics(self):
        """æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“Š è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯:")
        print("-" * 60)
        
        # æ€»ä½“ç»Ÿè®¡
        print(f"ğŸŒ æºå¤„ç†ç»Ÿè®¡:")
        print(f"   æ€»URLæ•°é‡: {self.stats['total_urls']}")
        print(f"   æˆåŠŸè·å–: {self.stats['success_urls']}")
        print(f"   é‡å¤å†…å®¹æº: {self.stats['total_urls'] - self.stats['success_urls']}")
        
        # é¢‘é“ç»Ÿè®¡
        print(f"\nğŸ“º é¢‘é“ç»Ÿè®¡:")
        print(f"   å”¯ä¸€é¢‘é“æ•°: {self.stats['unique_channels']:,}")
        print(f"   è¿‡æ»¤é‡å¤é¢‘é“æ•°: {self.stats['duplicate_channels']:,}")
        print(f"   æ€»å¤„ç†é¢‘é“æ•°: {self.stats['unique_channels'] + self.stats['duplicate_channels']:,}")
        
        # æ–‡ä»¶1ç»Ÿè®¡
        if self.file1_content:
            channels1 = sum(len(item["lines"]) - 1 for item in self.file1_content)
            categories1 = list(self.stats['file1_categories'])
            print(f"\nğŸ“ my1.txt (ç±»åˆ«åŒ¹é…: {', '.join(self.categories_file1)})")
            print(f"   åˆ†ç»„æ•°é‡: {len(self.file1_content)}")
            print(f"   é¢‘é“æ•°é‡: {channels1}")
            print(f"   åŒ…å«ç±»åˆ«: {', '.join(sorted(categories1)[:8])}")
            if len(categories1) > 8:
                print(f"             ... ç­‰{len(categories1)}ä¸ªç±»åˆ«")
        else:
            print(f"\nğŸ“ my1.txt: æ— åŒ¹é…å†…å®¹")
        
        # æ–‡ä»¶2ç»Ÿè®¡
        if self.file2_content:
            channels2 = sum(len(item["lines"]) - 1 for item in self.file2_content)
            categories2 = list(self.stats['file2_categories'])
            print(f"\nğŸ“ my2.txt (ç±»åˆ«åŒ¹é…: {', '.join(self.categories_file2)})")
            print(f"   åˆ†ç»„æ•°é‡: {len(self.file2_content)}")
            print(f"   é¢‘é“æ•°é‡: {channels2}")
            print(f"   åŒ…å«ç±»åˆ«: {', '.join(sorted(categories2)[:8])}")
            if len(categories2) > 8:
                print(f"             ... ç­‰{len(categories2)}ä¸ªç±»åˆ«")
        else:
            print(f"\nğŸ“ my2.txt: æ— åŒ¹é…å†…å®¹")


def main():
    """ä¸»å‡½æ•°"""
    processor = IPTVProcessor()
    
    try:
        processor.run()
        
        # éªŒè¯æ–‡ä»¶
        print("\nğŸ” æ–‡ä»¶éªŒè¯:")
        for filename in ["my1.txt", "my2.txt"]:
            try:
                if os.path.exists(filename):
                    size = os.path.getsize(filename)
                    lines_count = 0
                    with open(filename, 'r', encoding='utf-8') as f:
                        lines_count = len(f.readlines())
                    
                    print(f"   ğŸ“„ {filename}: {size:,} å­—èŠ‚, {lines_count} è¡Œ")
                else:
                    print(f"   âš ï¸  {filename}: æ–‡ä»¶æœªç”Ÿæˆ")
            except Exception as e:
                print(f"   âŒ {filename}: éªŒè¯å‡ºé”™ - {e}")
                
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
